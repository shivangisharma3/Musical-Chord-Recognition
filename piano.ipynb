{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy, scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "import numpy, scipy, matplotlib.pyplot as plt\n",
    "import librosa, librosa.display \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030698\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "chords=['c','c#','d','d#','e','f','f#','g','g#','a','a#','b','cm','c#m','dm','d#m','em','fm','f#m','gm','g#m','am','a#m','bm']\n",
    "notes=['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "starthop=512\n",
    "A=[]\n",
    "for i in range(len(chords)):\n",
    "    with open(\"piano_\"+str(256)+\"/\"+chords[i]+\".json\") as readfile :\n",
    "        a = readfile.read()\n",
    "    a = a.strip()\n",
    "    x = json.loads(a)\n",
    "    for j in range(len(x)):\n",
    "        sum=0\n",
    "        for su in range(12):\n",
    "            sum=sum+x[j][su]\n",
    "        if sum > 1:\n",
    "            x[j].append(i)\n",
    "            A.append(x[j])\n",
    "\n",
    "print(len(A))\n",
    "df = pd.DataFrame(A)\n",
    "df.columns = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B','Label']\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 257675 points : 188609, performance 26.80%\n"
     ]
    }
   ],
   "source": [
    "# Split dataset in training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size=0.25, random_state=int(time.time()))\n",
    "\n",
    "model = GaussianNB()\n",
    "used_features = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "# Train classifier\n",
    "model.fit(\n",
    "    X_train[used_features].values,\n",
    "    X_train[\"Label\"]\n",
    ")\n",
    "model_pred = model.predict(X_test[used_features])\n",
    "\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\" .format(X_test.shape[0],(X_test[\"Label\"] != model_pred).sum(),100*(1-(X_test[\"Label\"] != model_pred).sum()/X_test.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the Classifier\n",
    "gnb = GaussianNB()\n",
    "used_features = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "# Training the classifier\n",
    "gnb.fit(df[used_features].values,df[\"Label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For single instance Static Chord Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-91630b4bbfe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRATE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBUFF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mDuration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUFF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"finished recording\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "BUFF = 1024\n",
    "Duration = 10\n",
    "out = \"file.wav\"\n",
    " \n",
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(format=FORMAT, channels=2, rate=RATE, input=True, frames_per_buffer=BUFF)\n",
    "\n",
    "# for it in range(0,20):\n",
    "print (\"recording...\")\n",
    "frames = []\n",
    "for i in range(0, int(RATE / BUFF * Duration)):\n",
    "    data = stream.read(BUFF)\n",
    "    frames.append(data)\n",
    "print (\"finished recording\")\n",
    "\n",
    "# stop Recording\n",
    "\n",
    "waveFile = wave.open(out, 'wb')\n",
    "waveFile.setnchannels(2)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(frames))\n",
    "waveFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-Major with a match of  74.02672864613596 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivangi/anaconda3/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x, sr = librosa.load('file.wav')\n",
    "test = librosa.feature.chroma_stft(x, sr=sr, hop_length=128)\n",
    "list2=[]\n",
    "for j in range(len(test[0])):\n",
    "    a=[]\n",
    "    for k in range(12):\n",
    "        a.append(test[k][j])\n",
    "    list2.append(a)\n",
    "\n",
    "df2 = pd.DataFrame(list2)\n",
    "#print(type(df2))\n",
    "df2.columns = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "y_pred = gnb.predict(list2)\n",
    "\n",
    "acc={}\n",
    "for cho in range(len(chords)):\n",
    "    count = 0\n",
    "    for y in y_pred:\n",
    "        if y == cho : \n",
    "            count = count + 1\n",
    "    acc[chords[cho]]=count/len(y_pred)\n",
    "\n",
    "import operator\n",
    "\n",
    "s=max(acc.items(), key=operator.itemgetter(1))[0]\n",
    "i=chords.index(s)\n",
    "mid=(i+4)%12\n",
    "cname=notes[i%12]\n",
    "if i > 11:\n",
    "    mid=(3+i)%12\n",
    "    cname=cname+\"-Minor\"\n",
    "else:\n",
    "    cname=cname+\"-Major\"\n",
    "\n",
    "print (cname,\"with a match of \",acc[s]*100,\"%\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Chord Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying Chords\n",
      "A Major\n",
      "C Major\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8a98aa1fddee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRATE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBUF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "BUF = 1024\n",
    "duration = 2\n",
    "out = \"file.wav\"\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(format=FORMAT, channels=2, rate=RATE, input=True, frames_per_buffer=BUF)\n",
    "old=-1\n",
    "\n",
    "full=[]\n",
    "\n",
    "print(\"Identifying Chords\")\n",
    "for it in range(0,100):\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / BUF * duration)):\n",
    "        data = stream.read(BUF)\n",
    "        frames.append(data)\n",
    "        full.append(data)\n",
    "\n",
    "    # stop Recording\n",
    "    waveFile = wave.open(out, 'wb')\n",
    "    waveFile.setnchannels(2)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "\n",
    "    x, sr = librosa.load(out)\n",
    "    test = librosa.feature.chroma_stft(x, sr=sr, hop_length=128)\n",
    "    list2=[]\n",
    "    for j in range(len(test[0])):\n",
    "        a=[]\n",
    "        for k in range(12):\n",
    "            a.append(test[k][j])\n",
    "        list2.append(a)\n",
    "\n",
    "    df2 = pd.DataFrame(list2)\n",
    "    df2.columns = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "    y_pred = gnb.predict(list2)\n",
    "\n",
    "    acc={}\n",
    "    for cho in range(len(chords)):\n",
    "        count = 0\n",
    "        for y in y_pred:\n",
    "            if y == cho : \n",
    "                count = count + 1\n",
    "        acc[chords[cho]]=count/len(y_pred)\n",
    "\n",
    "    import operator\n",
    "\n",
    "    s=max(acc.items(), key=operator.itemgetter(1))[0]\n",
    "    i=chords.index(s)\n",
    "    mid=(i+4)%12\n",
    "    cname=notes[i%12]\n",
    "    if i > 11 :\n",
    "        mid=(3+i)%12\n",
    "        cname=cname+\" Minor\"\n",
    "    else:\n",
    "        cname=cname+\" Major\"\n",
    "    if old != i:\n",
    "        print (cname)\n",
    "    old=i\n",
    "print(\"Stopped\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "waveFile = wave.open(out, 'wb')\n",
    "waveFile.setnchannels(2)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(full))\n",
    "waveFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
